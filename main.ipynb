{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "vRgE-2ZK9aHv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2kvQQFDpP91"
      },
      "source": [
        "# **Image Augmentation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uOyEyKtMYflm"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, save_img\n",
        "\n",
        "data_dir = '/content/drive/MyDrive/Faulty_solar_panel'\n",
        "target_size = (224, 224)\n",
        "\n",
        "# Count images per class\n",
        "class_counts = {}\n",
        "for class_name in os.listdir(data_dir):\n",
        "    class_path = os.path.join(data_dir, class_name)\n",
        "    if os.path.isdir(class_path):\n",
        "        num_images = len([f for f in os.listdir(class_path) if f.endswith(('.jpg', '.png'))])\n",
        "        class_counts[class_name] = num_images\n",
        "\n",
        "# max_images from the largest class\n",
        "max_images = max(class_counts.values())\n",
        "print(\"Class distribution before augmentation:\")\n",
        "for k, v in class_counts.items():\n",
        "    print(f\"{k}: {v} images\")\n",
        "\n",
        "# Augmentation setup\n",
        "augmentor = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    zoom_range=0.15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# Augment images in smaller classes\n",
        "for class_name in os.listdir(data_dir):\n",
        "    class_path = os.path.join(data_dir, class_name)\n",
        "    if not os.path.isdir(class_path):\n",
        "        continue\n",
        "\n",
        "    images = [f for f in os.listdir(class_path) if f.endswith(('.jpg', '.png'))]\n",
        "    current_count = len(images)\n",
        "    target_count = max_images\n",
        "\n",
        "    if current_count >= target_count:\n",
        "        continue  # Skip already-balanced or larger classes\n",
        "\n",
        "    print(f\"\\nAugmenting '{class_name}' from {current_count} to {target_count}\")\n",
        "\n",
        "    i = 0\n",
        "    while current_count + i < target_count:\n",
        "        img_name = images[i % len(images)]\n",
        "        img_path = os.path.join(class_path, img_name)\n",
        "\n",
        "        img = load_img(img_path, target_size=target_size)\n",
        "        x = img_to_array(img)\n",
        "        x = x.reshape((1,) + x.shape)\n",
        "\n",
        "        for batch in augmentor.flow(x, batch_size=1):\n",
        "            new_filename = f\"aug_{i}_{img_name}\"\n",
        "            save_img(os.path.join(class_path, new_filename), batch[0])\n",
        "            break\n",
        "\n",
        "        i += 1\n",
        "\n",
        "print(\"\\n All classes are balanced!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hHtnRJxYraNK"
      },
      "outputs": [],
      "source": [
        "# After Augmentation counting classes\n",
        "class_counts = {}\n",
        "\n",
        "for class_folder in os.listdir(data_dir):\n",
        "    class_path = os.path.join(data_dir, class_folder)\n",
        "    if os.path.isdir(class_path):\n",
        "        num_images = len([f for f in os.listdir(class_path) if f.endswith(('.jpg', '.png', '.jpeg'))])\n",
        "        class_counts[class_folder] = num_images\n",
        "\n",
        "for class_name, count in class_counts.items():\n",
        "    print(f\"{class_name}: {count} images\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vi8QYdH6SlE-"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator # convert float into numarical and normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bAiOX_oRS3-F"
      },
      "outputs": [],
      "source": [
        "datagen = ImageDataGenerator(rescale = 1./255,validation_split=0.2)\n",
        "\n",
        "train_images = datagen.flow_from_directory('/content/drive/MyDrive/Faulty_solar_panel',target_size=(224, 224),batch_size=32,class_mode=\"categorical\",subset='training')\n",
        "\n",
        "test_images = datagen.flow_from_directory('/content/drive/MyDrive/Faulty_solar_panel',target_size=(224, 224),batch_size=32,class_mode=\"categorical\",subset=\"validation\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H5X8LUDsTLgN"
      },
      "outputs": [],
      "source": [
        "class_name = [\"Bird-drop\",\"Clean\",\"Dusty\",\"Electrical-damage\",\"Physical-Damage\",\"Snow-Covered\"]\n",
        "\n",
        "images,labels = next(train_images) #next - iteration\n",
        "\n",
        "for i in range(16):\n",
        "  plt.subplot(4,4,i+1)\n",
        "  plt.imshow(images[i])\n",
        "  class_labels=class_name[np.argmax(labels[i])]\n",
        "  plt.title(class_labels)\n",
        "  plt.grid(True)\n",
        "  plt.tight_layout()\n",
        "  plt.axis('off')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BX2yVANg4-qn"
      },
      "source": [
        "# **Custom Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FKu9igYNqG8K"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8b1LUsr-t4Mv"
      },
      "outputs": [],
      "source": [
        "custom_model = Sequential()\n",
        "\n",
        "custom_model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3))),\n",
        "custom_model.add(MaxPooling2D(2, 2))\n",
        "\n",
        "custom_model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "custom_model.add(MaxPooling2D(2, 2))\n",
        "\n",
        "custom_model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "custom_model.add(MaxPooling2D(2, 2))\n",
        "\n",
        "custom_model.add(Flatten())\n",
        "\n",
        "custom_model.add(Dense(128, activation='relu'))\n",
        "custom_model.add(Dropout(0.5))\n",
        "custom_model.add(Dense(100, activation=\"relu\"))\n",
        "\n",
        "custom_model.add(Dense(6, activation=\"softmax\"))  # 6 classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qqsry3si1Amq"
      },
      "outputs": [],
      "source": [
        "custom_model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vq32WYJP3YeV",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "history = custom_model.fit(\n",
        "    train_images,\n",
        "    epochs=20,\n",
        "    validation_data=test_images ,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8OfGC7aXI9i1"
      },
      "outputs": [],
      "source": [
        "custom_model.save('solar_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n-0Gf0ABJRXT"
      },
      "outputs": [],
      "source": [
        "#Prediction using cutom model\n",
        "\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "img_path = \"/content/sample3.jpg\"\n",
        "img = image.load_img(img_path, target_size=(224, 224))\n",
        "img_array = image.img_to_array(img)\n",
        "img_array = np.expand_dims(img_array, axis=0) / 255.0\n",
        "\n",
        "prediction = custom_model.predict(img_array)\n",
        "class_names = [\"Bird-drop\",\"Clean\",\"Dusty\",\"Electrical-damage\",\"Physical-Damage\",\"Snow-Covered\"]\n",
        "print(\"Predicted class:\", class_names[np.argmax(prediction)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BC2D6xclK-AO"
      },
      "outputs": [],
      "source": [
        "# Plotting Accuracy and Loss of the Custom model\n",
        "\n",
        "plt.plot(history.history[\"accuracy\"])\n",
        "plt.plot(history.history[\"val_accuracy\"])\n",
        "plt.title(\"Model Accuracy\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.legend([\"Train\", \"Validation\"], loc=\"upper left\")\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history[\"loss\"])\n",
        "plt.plot(history.history[\"val_loss\"])\n",
        "plt.title(\"Model Loss\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.legend([\"Train\", \"Validation\"], loc=\"upper left\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GIz28MH-LknZ"
      },
      "outputs": [],
      "source": [
        "y_pred = custom_model.predict(test_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-qFIeUcLLZfG"
      },
      "outputs": [],
      "source": [
        "confusion_matrix = tf.math.confusion_matrix(\n",
        "    labels=test_images.classes,\n",
        "    predictions=np.argmax(y_pred, axis=1)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cXF4oFtzLuma",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# plotting the confusion matrix\n",
        "\n",
        "sns.heatmap(confusion_matrix,annot=True,fmt='d')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title(\"Confusion matrix of Custom model\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RbzC2ocJmTgD"
      },
      "source": [
        "# **ReNet18**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall torch torchvision torchaudio --yes\n",
        "!pip cache purge\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121"
      ],
      "metadata": {
        "id": "9eNG2PTc57Wv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lA93nQSB-FCq"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import random_split\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Define transforms (resizing, normalization for ResNet18)\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load the dataset\n",
        "full_dataset = datasets.ImageFolder(root='/content/drive/MyDrive/Faulty_solar_panel', transform=transform)\n",
        "\n",
        "# Split the dataset into train and validation\n",
        "train_size = int(0.8 * len(full_dataset))\n",
        "val_size = len(full_dataset) - train_size\n",
        "\n",
        "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
        "\n",
        "# DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "print(f'Training dataset size: {len(train_dataset)}')\n",
        "print(f'Validation dataset size: {len(val_dataset)}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IGSrrzHloOb3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import  models\n",
        "\n",
        "\n",
        "# device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# hyperparameters\n",
        "num_classes = 6  # change to your number of classes\n",
        "batch_size = 32\n",
        "learning_rate = 0.001\n",
        "num_epochs = 10  # you can adjust\n",
        "\n",
        "#Load ResNet18\n",
        "model = models.resnet18(pretrained=True)\n",
        "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "model = model.to(device)\n",
        "\n",
        "# Loss and Optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Lists to store accuracy values\n",
        "train_accuracies = []\n",
        "val_accuracies = []\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "# Training Loop\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct_train = 0\n",
        "    total_train = 0\n",
        "\n",
        "    for images2, labels in train_loader:\n",
        "        images2 = images2.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images2)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total_train += labels.size(0)\n",
        "        correct_train += (predicted == labels).sum().item()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # average training loss and accuracy\n",
        "    train_accuracy = 100 * correct_train / total_train\n",
        "    avg_train_loss = running_loss / len(train_loader)\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Training Loss: {epoch_loss:.4f}\")\n",
        "\n",
        "  # Validation Loop\n",
        "    model.eval()\n",
        "    correct_val = 0\n",
        "    total_val = 0\n",
        "    running_val_loss = 0.0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct_val += (predicted == labels).sum().item()\n",
        "\n",
        "            # validation loss\n",
        "            running_val_loss += loss.item()\n",
        "    # average validation loss and accuracy\n",
        "    val_accuracy = 100 * correct_val / total\n",
        "    avg_val_loss = running_val_loss / len(val_loader)\n",
        "\n",
        "    # Appending the accuracies and losses\n",
        "    train_accuracies.append(train_accuracy)\n",
        "    val_accuracies.append(val_accuracy)\n",
        "    train_losses.append(avg_train_loss)\n",
        "    val_losses.append(avg_val_loss)\n",
        "    print(f\"Validation Accuracy: {val_accuracy:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0jCBVOOKRAf3"
      },
      "outputs": [],
      "source": [
        "# After training, plot accuracy and loss\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Plotting Training and Validation Accuracy of Resnet model\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(range(1, num_epochs + 1), train_accuracies, label='Training Accuracy', color='blue')\n",
        "plt.plot(range(1, num_epochs + 1), val_accuracies, label='Validation Accuracy', color='orange')\n",
        "plt.title('Training and Validation Accuracy of ResNet18')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# Plotting Training and Validation Loss of Resnet model\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(range(1, num_epochs + 1), train_losses, label='Training Loss', color='blue')\n",
        "plt.plot(range(1, num_epochs + 1), val_losses, label='Validation Loss', color='orange')\n",
        "plt.title('Training and Validation Loss ResNet18')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.savefig('Resnet_metrics.jpg')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images2, labels in val_loader:\n",
        "        images2, labels = images2.to(device), labels.to(device)\n",
        "\n",
        "        outputs = model(images2)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "print(cm)"
      ],
      "metadata": {
        "id": "AJ-fSwmL3uRq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion Matrix of ResNet\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.title('Confusion Matrix of ResNet')\n",
        "plt.savefig('confusion_matrix.jpg')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aVFVOFJn36Ao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jxRyGjEfLTmV"
      },
      "outputs": [],
      "source": [
        "# 9. Save the model after training\n",
        "torch.save(model.state_dict(), '/content/resnet18_2.pth')\n",
        "print(\"Model saved successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Prediction Using ResNet Model**"
      ],
      "metadata": {
        "id": "k1IixPHF6u7g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "\n",
        "# Load the trained model\n",
        "model.eval()\n",
        "\n",
        "#transforms\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# preprocess image\n",
        "img_path = '/content/drive/MyDrive/Faulty_solar_panel/Clean/Clean (100).jpg'\n",
        "image = Image.open(img_path).convert('RGB')\n",
        "image = transform(image)\n",
        "image = image.unsqueeze(0)  # Add batch dimension\n",
        "image = image.to(device)\n",
        "\n",
        "# Predict\n",
        "with torch.no_grad():\n",
        "    output = model(image)\n",
        "    _, predicted_class = torch.max(output, 1)\n",
        "\n",
        "# Class names\n",
        "class_names = [\"Bird-drop\",\"Clean\",\"Dusty\",\"Electrical-damage\",\"Physical-Damage\",\"Snow-Covered\"]\n",
        "predicted_label = class_names[predicted_class.item()]\n",
        "\n",
        "print(f\"Predicted Label: {predicted_label}\")\n"
      ],
      "metadata": {
        "id": "9z0ZB9MN5-qY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "class_names = [\"Bird-drop\",\"Clean\",\"Dusty\",\"Electrical-damage\",\"Physical-Damage\",\"Snow-Covered\"]\n",
        "print(classification_report(all_labels, all_preds, target_names=class_names))\n"
      ],
      "metadata": {
        "id": "Ehq78NjMKIfu"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
